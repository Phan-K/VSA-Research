{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Datasets for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Good vs Bad Plans Dataset\n",
    "Stored in an Excel file titled \"VSADataForClassification.xlsx\", consisting of 4 sheets.\n",
    "\n",
    "### Sheet names:\n",
    "1. Export Worksheet - All the data from the next two sheets combined\n",
    "2. GoodPlans - All good plans\n",
    "3. BadPlans - All bad plans\n",
    "4. SQL - Contains SQL code for retrieving from the database\n",
    "\n",
    "### Columns:\n",
    "1. PLANID - Plan ID Number\n",
    "2. ActualLengthOfPlan - Number of quarters total\n",
    "3. NumberOfQtrWithoutCourses - Number of quarters with no courses\n",
    "4. NumberOfQtrWithCourses - Number of quarters with at least one course\n",
    "5. TotalNumberOfCourses - Total courses in the plan\n",
    "6. AvgNumberOfCoursesPerQuarter - Average number of courses in a quarter\n",
    "7. TotalNumberOfYears - Number of years it takes to complete the plan\n",
    "8. NumberofYearswithCOurse - Number of years it takes to complete all the courses, not including breaks\n",
    "9. GapDelta\n",
    "10. FinalScore - Binary value of the plan, where 0 is Bad, and 1 is Good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# opening and storing the files of the dataset\n",
    "xl = pd.ExcelFile('VSADataForClassification.xlsx')\n",
    "df_good = xl.parse('GoodPlans')\n",
    "df_bad = xl.parse('BadPlans')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing the Dataset\n",
    "One of the important things in Machine Learning is having a balanced dataset, where a certain class is much more represented in the data than another. One method of balancing the dataset is to duplicate the minority data so that there is an equal number of data for each class.\n",
    "\n",
    "There are 286 good plans, and 1225 bad plans, meaning that the data is immbalanced. Therefore, to make it balanced, the good data is to be duplicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for generating random indices\n",
    "import random\n",
    "\n",
    "# randomly duplicate the good plans\n",
    "# so that there are an equal number of bad & good plans\n",
    "df_dup = df_bad.copy()\n",
    "for i in range(df_good.shape[0]):\n",
    "    df_dup.loc[i] = df_good.loc[i]    \n",
    "for i in range(286,df_bad.shape[0]):\n",
    "    index = random.randint(0,df_good.shape[0] - 1)\n",
    "    df_dup.loc[i] = df_good.loc[index]\n",
    "    \n",
    "# shuffle the duplicated good plans\n",
    "df_dup = df_dup.copy()\n",
    "df_dup = df_dup.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a combined dataset of good and bad plans\n",
    "df_total = pd.concat([df_dup, df_bad])\n",
    "# randomize the rows\n",
    "df_total = df_total.sample(frac=1).reset_index(drop=True)\n",
    "# drop uneeded features\n",
    "df_total = df_total.drop(['PLANID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the datasets\n",
    "df_dup.to_csv('VSA_new_good.csv', index=False)\n",
    "df_bad.to_csv('VSA_new_bad.csv', index=False)\n",
    "\n",
    "# export labels\n",
    "labels = df_total[['FinalScore']].copy()\n",
    "labels.to_csv('VSA_labels.csv')\n",
    "# export dataset\n",
    "df_total = df_total.drop(['FinalScore'], axis=1)\n",
    "df_total.to_csv('VSA_new_total.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the Dataset\n",
    "In a dataset, different features may have different scales. For example, if one feature is the age of a person, then the scale could be anywhere from 0-70. Meanwhile, another feature could be the length of their thumb, which could range anywhere from 2-10 cm. Because of the difference in scale, the effect of one feature on a classifier may have different weight.\n",
    "\n",
    "Therefore, it is important to scale the features and normalize them so that they have a similar scale. The features I am using are the averages, meaning that the first four columns will not be used.\n",
    "\n",
    "The following expression will be used to calculate the mean centered value:\n",
    "\n",
    "__(feature_mean - x) / feature_std__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean center the dataset except for the labels column\n",
    "df_norm = df_total.copy()\n",
    "for column in df_norm:\n",
    "    std = df_total[column].std()\n",
    "    mean = df_total[column].mean()\n",
    "    for i in range(df_total.shape[0]):\n",
    "        x = df_total.loc[i, column]     \n",
    "        df_norm.loc[i, column] = (mean - x) / std\n",
    "            \n",
    "# export this normalized dataset\n",
    "df_norm.to_csv('VSA_new_norm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Data\n",
    "Stored in a file called 'studyplans.csv'. \n",
    "\n",
    "### Columns:\n",
    "1. ID - The ID of the row\n",
    "2. PlanID - The ID of the plan\n",
    "3. QuarterID - The ID of the quarter. 4 is summer, 1 is fall, 2 is winter, and 3 is spring\n",
    "4. YearID - The year of the quarter\n",
    "5. CourseID - The class course number in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the file and load the data\n",
    "df = pd.read_csv('studyplans.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping each course to a plan ID in order\n",
    "Each course is mapped to a plan, in the sequential order which the student will take them. Each plan comprises one 'sentence' in which the courses in order are the words, and ends with the word \"EOS\".\n",
    "\n",
    "Example: Plan 9 consists of the courses 921 1170 264 1133. Therefore its corresponding sentence is: \"921 1170 264 1133 EOS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dictionary maps PlanID to a sequential list of sources\n",
    "plan_dict = {}\n",
    "for i, row in df.iterrows():\n",
    "    if row['PlanID'] not in plan_dict.keys():\n",
    "        course_list = []\n",
    "        plan_dict[row['PlanID']] = course_list\n",
    "    plan_dict[row['PlanID']].append(row['CourseID'])\n",
    "    \n",
    "# convert to a dataframe\n",
    "df_map = df[['PlanID']].copy()\n",
    "df_map['Sentence'] = 0\n",
    "df_map = df_map.drop_duplicates(['PlanID'])\n",
    "df_map['ind'] = df_map['PlanID']\n",
    "df_map = df_map.set_index('ind')\n",
    "for key in plan_dict:\n",
    "    sentence = \"\"\n",
    "    for course in plan_dict[key]:\n",
    "        sentence += str(course) + \" \"\n",
    "    sentence += \"EOS\"\n",
    "    df_map.loc[key, 'Sentence'] = sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create CSV\n",
    "df_map.to_csv('studyplan_sentences.csv')\n",
    "\n",
    "# make a document containing all sentences\n",
    "document = \"\"\n",
    "for key in plan_dict:\n",
    "    document += df_map.loc[key, 'Sentence'] + \" \"\n",
    "with open('studyplan_document.txt', 'w') as textfile:\n",
    "    textfile.write(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
